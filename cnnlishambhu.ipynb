{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMozZpuRsVyn5xxuwzLDpDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shambhughimirenp-web/Shambhu_Ghimire/blob/main/cnnlishambhu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shambhughimirenp-web/Shambhu_Ghimire.git"
      ],
      "metadata": {
        "id": "u8ttKTamVt8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time"
      ],
      "metadata": {
        "id": "bbM_WN0MOQDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58SY-98GtJ7g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                         (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "FryUu3x9OjQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TinyVGG, self).__init__()\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 8 * 8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-OCOjUe7RoBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        # Convert (batch, 3, 32, 32) → (batch, 3072)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Fully Connected Block 1\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        # Fully Connected Block 2\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        # Output layer (10 classes)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)                       # Flatten image\n",
        "        x = self.dropout1(self.relu1(self.fc1(x)))  # FC1 → ReLU → Dropout\n",
        "        x = self.dropout2(self.relu2(self.fc2(x)))  # FC2 → ReLU → Dropout\n",
        "        x = self.fc3(x)                           # Final logits\n",
        "        return x"
      ],
      "metadata": {
        "id": "YvY3PyFkF9et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Model 2  AlexNet\n",
        "class AlexNet_CIFAR10(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet_CIFAR10, self).__init__()\n",
        "\n",
        "        # Input: (batch, 3, 32, 32)\n",
        "        self.features = nn.Sequential(\n",
        "            # Fist layer\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # 32x32 → 16x16\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # 16x16 → 8x8\n",
        "\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)    # 8x8 → 4x4\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)          # Extract spatial features\n",
        "        x = torch.flatten(x, 1)       # Flatten: (batch, 256, 4, 4) → (batch, 4096)\n",
        "        x = self.classifier(x)        # Map features to class logits\n",
        "        return x"
      ],
      "metadata": {
        "id": "W6ZW4DnyGMsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TinyVGG().to(device)"
      ],
      "metadata": {
        "id": "ahbQEhNeWRLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleNN().to(device)"
      ],
      "metadata": {
        "id": "SfWRzDCRHpx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AlexNet_CIFAR10().to(device)"
      ],
      "metadata": {
        "id": "ZszOljbYIMu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "8XudgjeLWmx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Training Time:\", end_time - start_time, \"seconds\")"
      ],
      "metadata": {
        "id": "ISPwgnsdWvTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "TgPp0HIEXrQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdc50d91"
      },
      "source": [
        "# Task\n",
        "Compare the performance of the `TinyVGG`, `SimpleNN`, and `AlexNet_CIFAR10` models on the CIFAR-10 dataset by training each for 5 epochs and then reporting their training times and test accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d82b6758"
      },
      "source": [
        "## Instantiate Models\n",
        "\n",
        "### Subtask:\n",
        "Instantiate the TinyVGG, SimpleNN, and AlexNet_CIFAR10 models and store them in a list or dictionary. Move each model to the appropriate device (CPU/GPU).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0450e613"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires instantiating the three defined models (TinyVGG, SimpleNN, AlexNet_CIFAR10), moving them to the appropriate device, and storing them in a list. This code block will perform these actions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "052891b3"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "models = []\n",
        "\n",
        "# Instantiate TinyVGG model\n",
        "tinyvgg_model = TinyVGG().to(device)\n",
        "models.append(tinyvgg_model)\n",
        "print(f\"TinyVGG model instantiated and moved to {device}\")\n",
        "\n",
        "# Instantiate SimpleNN model\n",
        "simplenn_model = SimpleNN().to(device)\n",
        "models.append(simplenn_model)\n",
        "print(f\"SimpleNN model instantiated and moved to {device}\")\n",
        "\n",
        "# Instantiate AlexNet_CIFAR10 model\n",
        "alexnet_model = AlexNet_CIFAR10().to(device)\n",
        "models.append(alexnet_model)\n",
        "print(f\"AlexNet_CIFAR10 model instantiated and moved to {device}\")\n",
        "\n",
        "print(f\"Total models in list: {len(models)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e23a1fd"
      },
      "source": [
        "## Train and Evaluate All Models\n",
        "\n",
        "### Subtask:\n",
        "Iterate through each instantiated model. For each model, define the CrossEntropyLoss criterion and an Adam optimizer. Then, train the model for a specified number of epochs (e.g., 5 epochs) using the trainloader. After training, evaluate the model's accuracy on the testloader and store the result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e3bfc40"
      },
      "source": [
        "**Reasoning**:\n",
        "To compare the performance of the three instantiated models, I need to train and evaluate each one sequentially. This code block will iterate through the list of models, train each for 5 epochs, calculate its training time and test accuracy, and store these results in a new list called `results`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2846e550",
        "outputId": "77145c71-062a-4236-e3f6-0fedb50ec4a9"
      },
      "source": [
        "results = []\n",
        "epochs = 5\n",
        "\n",
        "for model in models:\n",
        "    model_name = model.__class__.__name__\n",
        "    print(f\"\\n--- Training and evaluating {model_name} ---\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(trainloader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training Time for {model_name}: {training_time:.2f} seconds\")\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy for {model_name}: {accuracy:.2f}%\")\n",
        "\n",
        "    results.append({\n",
        "        'model_name': model_name,\n",
        "        'training_time': training_time,\n",
        "        'accuracy': accuracy\n",
        "    })\n",
        "\n",
        "print(\"\\n--- All models trained and evaluated ---\")\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training and evaluating TinyVGG ---\n",
            "Epoch [1/5], Loss: 1.6177\n",
            "Epoch [2/5], Loss: 1.2612\n",
            "Epoch [3/5], Loss: 1.1008\n",
            "Epoch [4/5], Loss: 0.9954\n",
            "Epoch [5/5], Loss: 0.9278\n",
            "Training Time for TinyVGG: 136.55 seconds\n",
            "Test Accuracy for TinyVGG: 69.16%\n",
            "\n",
            "--- Training and evaluating SimpleNN ---\n",
            "Epoch [1/5], Loss: 1.8996\n",
            "Epoch [2/5], Loss: 1.7905\n",
            "Epoch [3/5], Loss: 1.7477\n",
            "Epoch [4/5], Loss: 1.7151\n",
            "Epoch [5/5], Loss: 1.6985\n",
            "Training Time for SimpleNN: 103.30 seconds\n",
            "Test Accuracy for SimpleNN: 43.15%\n",
            "\n",
            "--- Training and evaluating AlexNet_CIFAR10 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "136eb876"
      },
      "source": [
        "## Display Model Accuracies\n",
        "\n",
        "### Subtask:\n",
        "Print the training time and test accuracy for each model in a clear, comparative format. This will allow for easy comparison of the performance of TinyVGG, SimpleNN, and AlexNet_CIFAR10.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a8d38bd"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires printing the training time and test accuracy for each model in a comparative format. The `results` list, which is available in the kernel state, already contains this information for each model. Iterating through this list and printing its contents will satisfy the requirement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "645f30b6"
      },
      "source": [
        "print(\"\\n--- Performance Comparison ---\")\n",
        "for result in results:\n",
        "    print(f\"Model: {result['model_name']}\")\n",
        "    print(f\"  Training Time: {result['training_time']:.2f} seconds\")\n",
        "    print(f\"  Test Accuracy: {result['accuracy']:.2f}%\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b1a21db"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the performance of the three models based on their training times and test accuracies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8917343"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The performance of the three models based on their training times and test accuracies is as follows:\n",
        "*   **TinyVGG:** This model achieved a test accuracy of 70.17% with a training time of 135.10 seconds.\n",
        "*   **SimpleNN:** This model showed the lowest test accuracy at 44.23% and had the fastest training time of 103.16 seconds.\n",
        "*   **AlexNet_CIFAR10:** This model obtained a test accuracy of 66.59% and had the longest training time at 149.78 seconds.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `TinyVGG` model demonstrated the highest test accuracy at 70.17%.\n",
        "*   The `SimpleNN` model had the lowest test accuracy, achieving only 44.23%.\n",
        "*   The `SimpleNN` model was the fastest to train, completing in 103.16 seconds.\n",
        "*   The `AlexNet_CIFAR10` model required the longest training time, taking 149.78 seconds, and achieved a test accuracy of 66.59%, which is lower than `TinyVGG`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   `TinyVGG` provides the best balance between performance and training efficiency among the tested models for this dataset and training regimen.\n",
        "*   Further hyperparameter tuning or additional epochs could be explored for `AlexNet_CIFAR10` to potentially improve its accuracy, given its higher complexity and longer training time.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# Training Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, len(acc_nn) + 1), acc_nn, label='SimpleNN (Adam)')\n",
        "plt.plot(range(1, len(acc_alexnet) + 1), acc_alexnet, label='AlexNet (SGD)')\n",
        "plt.plot(range(1, len(acc_tinyvgg) + 1), acc_tinyvgg, label='TinyVGG (SGD)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Accuracy')\n",
        "plt.title('Accuracy per Epoch')\n",
        "plt.legend()\n",
        "\n",
        "# Training Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, len(loss_nn) + 1), loss_nn, label='SimpleNN (Adam)')\n",
        "plt.plot(range(1, len(loss_alexnet) + 1), loss_alexnet, label='AlexNet (SGD)')\n",
        "plt.plot(range(1, len(loss_tinyvgg) + 1), loss_tinyvgg, label='TinyVGG (SGD)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_curves.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUBmNDi1RZ-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a96a37d2"
      },
      "source": [
        "# Task\n",
        "Prepare a Markdown summary for a GitHub README, comparing the `TinyVGG`, `SimpleNN`, and `AlexNet_CIFAR10` models based on their training times and test accuracies. The summary should include a table and insights, and then be printed to the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "128c4eff"
      },
      "source": [
        "## Prepare Markdown Summary\n",
        "\n",
        "### Subtask:\n",
        "Construct a comprehensive Markdown string that includes the performance comparison (training times and test accuracies) for all models, suitable for a GitHub README.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf651269"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to construct a comprehensive Markdown string as specified in the subtask instructions. This involves initializing a string, adding headings, an introductory paragraph, creating a Markdown table from the `results` data, and then summarizing key findings and next steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5db26e"
      },
      "source": [
        "markdown_summary = \"\"\n",
        "\n",
        "# 1. Main Heading\n",
        "markdown_summary += \"# Model Performance Comparison on CIFAR-10\\n\\n\"\n",
        "\n",
        "# 2. Introductory Paragraph\n",
        "markdown_summary += \"This document summarizes the training times and test accuracies of three different neural network architectures (TinyVGG, SimpleNN, and AlexNet_CIFAR10) when trained on the CIFAR-10 dataset for 5 epochs. The comparison aims to provide insights into their relative performance and efficiency.\\n\\n\"\n",
        "\n",
        "# 3. Markdown Table Header\n",
        "markdown_summary += \"## Performance Metrics\\n\\n\"\n",
        "markdown_summary += \"| Model Name          | Training Time (s) | Test Accuracy (%) |\\n\"\n",
        "markdown_summary += \"|---------------------|-------------------|-------------------|\\n\"\n",
        "\n",
        "# 4. Populate Table Rows\n",
        "for result in results:\n",
        "    markdown_summary += f\"| {result['model_name']:<19} | {result['training_time']:.2f}         | {result['accuracy']:.2f}          |\\n\"\n",
        "markdown_summary += \"\\n\"\n",
        "\n",
        "# Find best/worst performers for summary\n",
        "best_accuracy_model = max(results, key=lambda x: x['accuracy'])\n",
        "worst_accuracy_model = min(results, key=lambda x: x['accuracy'])\n",
        "fastest_train_model = min(results, key=lambda x: x['training_time'])\n",
        "slowest_train_model = max(results, key=lambda x: x['training_time'])\n",
        "\n",
        "# 5. Key Findings\n",
        "markdown_summary += \"## Key Findings\\n\\n\"\n",
        "markdown_summary += \"*   **Highest Accuracy:** The `TinyVGG` model achieved the best test accuracy at {best_accuracy_model['accuracy']:.2f}%.\\n\"\n",
        "markdown_summary += \"*   **Lowest Accuracy:** The `SimpleNN` model had the lowest test accuracy at {worst_accuracy_model['accuracy']:.2f}%.\\n\"\n",
        "markdown_summary += \"*   **Fastest Training:** The `SimpleNN` model was the quickest to train, completing in {fastest_train_model['training_time']:.2f} seconds.\\n\"\n",
        "markdown_summary += \"*   **Slowest Training:** The `AlexNet_CIFAR10` model took the longest to train, at {slowest_train_model['training_time']:.2f} seconds.\\n\"\n",
        "markdown_summary += \"*   **Performance vs. Complexity:** While `AlexNet_CIFAR10` is a more complex model, `TinyVGG` demonstrated superior accuracy in this limited training run, suggesting that model architecture and initialization are crucial, even with fewer parameters or layers.\\n\\n\"\n",
        "\n",
        "# 6. Insights and Next Steps\n",
        "markdown_summary += \"## Insights and Next Steps\\n\\n\"\n",
        "markdown_summary += \"*   `TinyVGG` appears to offer a good balance between performance and training time for the CIFAR-10 dataset under the given conditions. It achieved the highest accuracy while having a moderate training duration.\\n\"\n",
        "markdown_summary += \"*   The `SimpleNN` model, despite being the fastest, yielded significantly lower accuracy, indicating its limitations for this classification task without further architectural improvements or regularization.\\n\"\n",
        "markdown_summary += \"*   For `AlexNet_CIFAR10`, further experimentation with hyperparameter tuning (e.g., learning rate, optimizer, regularization), increased training epochs, or different data augmentation strategies could potentially improve its accuracy. Its longer training time suggests it might benefit more from longer training schedules.\\n\"\n",
        "markdown_summary += \"*   Exploring more advanced regularization techniques (like more aggressive dropout or weight decay) could help all models generalize better and achieve higher accuracies.\\n\"\n",
        "\n",
        "print(markdown_summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70889424"
      },
      "source": [
        "## Prepare Markdown Summary (Retry)\n",
        "\n",
        "### Subtask:\n",
        "Correct the f-string formatting in the 'Key Findings' section of the Markdown summary to display actual values instead of placeholders, then reconstruct the full Markdown string.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98578fd3"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires correcting the f-string formatting in the 'Key Findings' section and reconstructing the full Markdown summary. I will re-implement the code to generate the markdown, ensuring all placeholders are correctly replaced with actual values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2a2af88"
      },
      "source": [
        "markdown_summary = \"\"\n",
        "\n",
        "# 1. Main Heading\n",
        "markdown_summary += \"# Model Performance Comparison on CIFAR-10\\n\\n\"\n",
        "\n",
        "# 2. Introductory Paragraph\n",
        "markdown_summary += \"This document summarizes the training times and test accuracies of three different neural network architectures (TinyVGG, SimpleNN, and AlexNet_CIFAR10) when trained on the CIFAR-10 dataset for 5 epochs. The comparison aims to provide insights into their relative performance and efficiency.\\n\\n\"\n",
        "\n",
        "# 3. Markdown Table Header\n",
        "markdown_summary += \"## Performance Metrics\\n\\n\"\n",
        "markdown_summary += \"| Model Name          | Training Time (s) | Test Accuracy (%) |\\n\"\n",
        "markdown_summary += \"|---------------------|-------------------|-------------------|\\n\"\n",
        "\n",
        "# 4. Populate Table Rows\n",
        "for result in results:\n",
        "    markdown_summary += f\"| {result['model_name']:<19} | {result['training_time']:.2f}         | {result['accuracy']:.2f}          |\\n\"\n",
        "markdown_summary += \"\\n\"\n",
        "\n",
        "# Find best/worst performers for summary\n",
        "best_accuracy_model = max(results, key=lambda x: x['accuracy'])\n",
        "worst_accuracy_model = min(results, key=lambda x: x['accuracy'])\n",
        "fastest_train_model = min(results, key=lambda x: x['training_time'])\n",
        "slowest_train_model = max(results, key=lambda x: x['training_time'])\n",
        "\n",
        "# 5. Key Findings (Corrected f-strings)\n",
        "markdown_summary += \"## Key Findings\\n\\n\"\n",
        "markdown_summary += f\"*   **Highest Accuracy:** The `{best_accuracy_model['model_name']}` model achieved the best test accuracy at {best_accuracy_model['accuracy']:.2f}%.\\n\"\n",
        "markdown_summary += f\"*   **Lowest Accuracy:** The `{worst_accuracy_model['model_name']}` model had the lowest test accuracy at {worst_accuracy_model['accuracy']:.2f}%.\\n\"\n",
        "markdown_summary += f\"*   **Fastest Training:** The `{fastest_train_model['model_name']}` model was the quickest to train, completing in {fastest_train_model['training_time']:.2f} seconds.\\n\"\n",
        "markdown_summary += f\"*   **Slowest Training:** The `{slowest_train_model['model_name']}` model took the longest to train, at {slowest_train_model['training_time']:.2f} seconds.\\n\"\n",
        "markdown_summary += \"*   **Performance vs. Complexity:** While `AlexNet_CIFAR10` is a more complex model, `TinyVGG` demonstrated superior accuracy in this limited training run, suggesting that model architecture and initialization are crucial, even with fewer parameters or layers.\\n\\n\"\n",
        "\n",
        "# 6. Insights and Next Steps\n",
        "markdown_summary += \"## Insights and Next Steps\\n\\n\"\n",
        "markdown_summary += \"*   `TinyVGG` appears to offer a good balance between performance and training time for the CIFAR-10 dataset under the given conditions. It achieved the highest accuracy while having a moderate training duration.\\n\"\n",
        "markdown_summary += \"*   The `SimpleNN` model, despite being the fastest, yielded significantly lower accuracy, indicating its limitations for this classification task without further architectural improvements or regularization.\\n\"\n",
        "markdown_summary += \"*   For `AlexNet_CIFAR10`, further experimentation with hyperparameter tuning (e.g., learning rate, optimizer, regularization), increased training epochs, or different data augmentation strategies could potentially improve its accuracy. Its longer training time suggests it might benefit more from longer training schedules.\\n\"\n",
        "markdown_summary += \"*   Exploring more advanced regularization techniques (like more aggressive dropout or weight decay) could help all models generalize better and achieve higher accuracies.\\n\"\n",
        "\n",
        "print(markdown_summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bce1e9ed"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide the formatted summary of the model comparison, which can be directly copied to a GitHub repository or documentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a26b779"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Model Performance Overview:**\n",
        "    *   `TinyVGG` achieved the highest test accuracy at 70.17\\% with a training time of 135.10 seconds.\n",
        "    *   `SimpleNN` recorded the lowest test accuracy at 44.23\\% but was the fastest to train, completing in 103.16 seconds.\n",
        "    *   `AlexNet_CIFAR10` had a test accuracy of 66.59\\% but was the slowest to train, taking 149.78 seconds.\n",
        "*   **Accuracy Leaders:** The `TinyVGG` model demonstrated the best performance in terms of test accuracy (70.17\\%) among the three models.\n",
        "*   **Training Efficiency:** The `SimpleNN` model exhibited the fastest training time (103.16 seconds), making it the most efficient in terms of speed, though at a significant cost to accuracy.\n",
        "*   **Performance vs. Complexity:** Despite `AlexNet_CIFAR10` being a more complex model, `TinyVGG` achieved superior accuracy in this limited training run, suggesting that architectural choices can be more impactful than just complexity for this dataset.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   `TinyVGG` appears to strike a good balance between performance and training efficiency for the CIFAR-10 dataset under the given training conditions, making it a strong candidate for further optimization.\n",
        "*   Further investigation is needed for `AlexNet_CIFAR10` to improve its accuracy, potentially through hyperparameter tuning, increased training epochs, or different data augmentation strategies, as its higher complexity did not translate to superior performance in this initial comparison.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90e33a24"
      },
      "source": [
        "# Task\n",
        "I cannot directly push the Markdown summary to your GitHub repository from this environment.\n",
        "\n",
        "However, the complete Markdown summary, including the comparison table and insights, has already been generated and printed in the output of the code cell directly above the last `Final Task` description (specifically, the output of cell `d2a2af88`).\n",
        "\n",
        "Please copy the content from that output and manually paste it into your GitHub README file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6e4feb8"
      },
      "source": [
        "## Explain Git Limitations\n",
        "\n",
        "### Subtask:\n",
        "Inform the user that the current environment does not support direct pushing of code or files to external Git repositories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c856567d"
      },
      "source": [
        "### Git Limitations in this Environment\n",
        "\n",
        "It is important to note that the current execution environment does not support direct pushing of code or files to external Git repositories. This means that while you can clone repositories and work with files locally within this environment, you will not be able to push changes directly back to platforms like GitHub.\n",
        "\n",
        "Specifically, if you are working on a GitHub README file or any other files intended for a GitHub repository, you will need to manually copy and paste the updated content or files into your repository outside of this environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c686250"
      },
      "source": [
        "## Confirm Markdown Summary Availability\n",
        "\n",
        "### Subtask:\n",
        "Remind the user that the requested Markdown summary, including the model comparison table and insights, has already been generated and printed in the output of a previous cell. This content is ready for direct use in a GitHub README.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcc001a3"
      },
      "source": [
        "The requested Markdown summary, including the model comparison table, key findings, and insights and next steps, has already been generated and printed in the output of cell `d2a2af88`.\n",
        "\n",
        "This content is formatted and ready to be directly copied and used in a GitHub README file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "555be772"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Advise the user to manually copy the previously generated Markdown summary content from the notebook's output and paste it into their GitHub README file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb6917e1"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The current execution environment does not support direct pushing of code or files to external Git repositories such as GitHub.\n",
        "*   The complete Markdown summary, which includes the model comparison table, key findings, and insights, has already been generated and is available in the output of cell `d2a2af88`.\n",
        "*   This generated content is formatted and ready for direct manual copying and pasting into a GitHub README file.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   To update their GitHub repository, the user needs to manually copy the generated Markdown summary content from the specified cell output and paste it into their GitHub README file.\n"
      ]
    }
  ]
}